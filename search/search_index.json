{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>This is the homepage of docs</p>"},{"location":"acads/sem6/Timetable/","title":"Timetable","text":"8:00-8:50 9:00-9:50 10:00-10:50 11:00-11:50 12:05-12:55 Break 14:00-16:45 17:10-18:00 Monday DBMS CD CD Lab Wednesday CD Friday DBMS CD DBMS Lab 8:00-8:50 9:00-10:15 10:30-11:45 12:00-12:50 Break 14:00-15:15 15:30-16:45 17:10-18:00 Tuesday DBMS NLP MC GTM Thursday NLP GTM MC MC"},{"location":"acads/sem6/compiler_design/","title":"Compiler Design","text":"<p>This is the homepage of the Compiler Design.</p>"},{"location":"acads/sem6/game_theory/","title":"gameTheory","text":"<p>This is the homepage of the Game Theory.</p>"},{"location":"acads/sem6/model_checking/","title":"Model Checking","text":""},{"location":"acads/sem6/model_checking/#tla","title":"TLA+","text":"<p>The TLA toolbox has the TLC model checking and TLAPS.</p> <p>The properties that TLA+ checks:</p> <ul> <li>Doesn't produce a wrong answer</li> <li>Checks conditions on individual executions, not statistical conclusions</li> </ul> <p>A step is a change of state.</p> <p>An execution is a represented as a sequence of states.</p> <p>TLA does not support generalizations</p> <p>See how to import a model to another file. verify the counter </p>"},{"location":"acads/sem6/model_checking/#state-machine","title":"State Machine","text":"<p>Definded by:</p> <ol> <li>All possible initial states</li> <li>What next states can follow in any given state</li> </ol>"},{"location":"learning/dna_computing/","title":"DNA Computing","text":""},{"location":"learning/dna_computing/#introduction","title":"Introduction","text":"<p>Uses DNA, biochemistry and molecular biology hardware instead of traditional silicon ones. Sub-field of DNA nanoscience(self assembly etc).</p> <p>Problem - specifically talking about Adleman's experiment, the components required grows exponentially as the number of nodes in the graph grows.  </p> <p>Further reading</p> <p>Slow speed(response time is in minutes, hours or days) is compensated by high potential for parallelism. However for exponential space problems, amount of DNA required is too large to be practical.</p> <p>Also, it is more difficult to analyze the results compared to a digital computer. </p>"},{"location":"learning/dna_computing/#adlemans-1994-paper","title":"Adleman's 1994 Paper","text":""},{"location":"learning/dna_computing/#problem","title":"Problem","text":"<p>The paper explained how DNA moleecules were used to encode a graph  to solve an instance of the directed Hamiltonian path problem. </p> <p>A directed graph $G$ with designated vertices $v_{in}$ and $v_{out}$ is said to have a Hamiltonian path if and only if $\\exists$ a path that begins at $v_{in}$, ends at $v_{out}$ and enters every other vertex exactly once.</p> <p>Some combinations of start and end vertices may not have Hamiltonian path(s).</p> <p>There are algorithms for determining whether an arbitrary directed graph with designated vertices has a hamiltonian path. But all of them have  exponential worst case running time. The directed Hamiltonian path problem is also NP-complete.  </p> <pre><code>    # A non-deterministic algorithm for solving directed Hamiltonian Path problem\n\n    '''\n        Step 1: Generate random paths through the graph\n        Step 2: Only keep paths starting from v_in and ending at v_out\n        Step 3: If graph has n vertices, keep paths that enter exactly n vertices\n        Step 4: Only keep paths that enter all vertices in the graph exactly once\n        Step 5: 'Yes' if paths remaining otherwise 'No'\n    '''\n</code></pre>"},{"location":"learning/dna_computing/#implementation","title":"Implementation","text":"<p>To implement step 1 of the algorithm, each vertex $i$ in the graph was associated with a random 20-mer(a sequence of 20 nucleotides) of DNA denoted $O_i$.</p>"},{"location":"learning/dna_computing/#results","title":"Results","text":""},{"location":"learning/dna_computing/#errors","title":"Errors","text":""},{"location":"learning/dna_computing/#advantages","title":"Advantages","text":""},{"location":"learning/dna_computing/#remarks","title":"Remarks","text":""},{"location":"learning/dp/","title":"DNA-Protein interaction","text":"<p>Date: 11/12/2025 </p>"},{"location":"learning/dp/#index","title":"Index","text":"<ol> <li>Inside a PDB file</li> <li>About the specific experiment</li> <li>Notes</li> </ol> <p>Aim: No idea, right now trying to come up with code to calculate distance between atoms from some protein database.  </p> <pre><code>Mathematically defining binding site based on atomic distance by treating biological molecules as geometric data points.\n</code></pre> <p></p>"},{"location":"learning/dp/#inside-a-pdb-file","title":"Inside a PDB file","text":"<pre><code>* Structure : Represents the entire outcome of the experiment. Contains everything in the 'test tube' - protein, DNA, water molecules, ions etc.\n\n* Model : Not quite clear on this one. In X-ray crystallography the protein is frozen. So there is only one model.\n          But if it is say NMR Spectroscopy the protein can move which gives rise to multiple models.\n\n* Chain : The covalently bonded molecules. List of objects identified by their ID's like 'A', 'B'...\n          eg: protein(polypeptide chain), dna(polynucleotide chain).\n\n* Residue : Protein residues(amino acids) and dna residues(A, C, G, T).\n\n* Atom : ...\n\nMetadata is stored in `structure.header` dictionary.\n\nThe *REMARKS* section mentions specific details about the experiment like error estimates, equipment/method used.\n\nBio.PDB creates the structure, model, chain, residue and atom objects after parsing the file.\n\n|Col|Content|Bio.PDB Object Created/Updated|Explanation|\n|:---|:---|:---|:--|\n|1-4|ATOM|Type Check|\"Tells parser: \"\"This is a real piece of the molecule.\"\"\"|\n|7-11|1|Atom.serial_number|Unique ID of the atom in the file.|\n|13-16|O5'|Atom.name|The Dictionary Key. This is the Oxygen at the 5' end.|\n|18-20|DT|Residue.resname|\"\"\"Deoxy-Thymidine\"\" (DNA T).\"|\n|22|E|Chain ID|\"The parser looks for Chain['E']. If it doesn't exist| it creates it.\"|\n|23-26|1001|Residue ID|\"The parser looks for residue 1001 inside Chain E. If not found| it creates Residue['1001'].\"|\n|31-54|25.930...|Atom.coord|\"A NumPy array [x| y| z]. This is what you subtract to get distance.\"|\n|77-78|O|Atom.element|Tells the parser this is Oxygen (for mass calc).|\n\nAtoms have attribiutes that specify which residue that they belong to and what the type of residue is. eg: Heteroatoms\nExplicit non-standard bonds.\n</code></pre>"},{"location":"learning/dp/#about-the-specific-experiment","title":"About the specific experiment","text":"<p>Apparently p53, the protein in the specific PDB file that I first saw(1TUP) is a pretty important protein. Functions include 'turning on' specific genes, acting as a tumor suppressor. It exists as a tetramer but for the experiments, 3 chains were isolated into the crystal.</p> <p>This makes 1TUP an excellent dataset for studying Binding, but a bad dataset for studying Oligomerization (how the 4 pieces stick together).</p> <p></p>"},{"location":"learning/dp/#notes","title":"Notes","text":"<ul> <li>Seaborn works on top of matplotlib so will have to import matplotlib while working with seaborn</li> </ul>"},{"location":"learning/dsa/","title":"DSA","text":""},{"location":"learning/dsa/#dynamic-programming","title":"Dynamic Programming","text":"<p>Dynamic programming can be applied if the problem can be divided into overlapping subproblems that can be solved independently.</p> <p>Two uses:     * Finding optimal solution     * Counting number of solutions</p>"},{"location":"learning/dsa/#types","title":"Types","text":"<ol> <li>Coin problem</li> <li>Longest Increasing Subsequence</li> <li>Paths in a grid</li> <li>Knapsack</li> <li>Edit distance</li> <li>Counting tilings</li> </ol>"},{"location":"learning/dsa/#greedy-algorithms","title":"Greedy algorithms","text":"<p>Constructs a solution by making the 'best' choice at the moment.  The locally optimal choices in a greedy algorithm should also be globally optimal. It is often difficult to argue that a greedy algorithm works.</p>"},{"location":"learning/dsa/#1-coin-problem","title":"1. Coin problem","text":"<pre><code>    In case of euro coins {1, 2, 5, 10, 20, 50, 100, 200}\n\n    We can show for each coin x that it is not possible  \n    to optimally construct a sum x or any larger sum by only using coins that are  \n    smaller than x. For example, if x = 100, the largest optimal sum using the smaller  \n    coins is 50+20+20+5+2+2 = 99. Thus, the greedy algorithm that always selects  \n    the largest coin produces the optimal solution.  \n\n    **NOTE** - Greedy algorithm would **not** work in general case.  \n            eg: 6 using {1, 3, 4}\n\n    It is not known if the general coin problem can be solved using any greedy\n    algorithm. However, it is possible to *check* in polynomial time if the greedy approach\n    works for a given set of coins.\n</code></pre>"},{"location":"learning/dsa/#2-scheduling","title":"2.  Scheduling","text":"<p>Given n events with their starting and ending times, find a schedule that includes as many events as possible.</p> <pre><code>    Appraoch: Select the next possible event that ends as soon as possible.\n\n    Correctness argument: consider what happens if we\n    first select an event that ends later than the event that ends as early as possible.\n    Now, we will have at most an equal number of choices how we can select the next\n    event.\n</code></pre>"},{"location":"learning/dsa/#tasks-and-deadlines","title":"Tasks and Deadlines","text":"<p>Given n tasks with durations and deadlines. For each task, we earn d \u2212 x points where d is the task\u2019s deadline and x is the moment when we finish the task. Choose an order to perform the tasks. Find largest possible score.</p> <pre><code>    Surprisingly, the optimal solution to the problem does not depend on the\n    deadlines at all, but a correct greedy strategy is to simply perform the tasks\n    sorted by their durations in increasing order.\n\n\n</code></pre>"},{"location":"learning/ml/","title":"Machine Learning","text":""},{"location":"learning/ml/#introduction","title":"Introduction","text":""},{"location":"learning/ml/#resources-used","title":"Resources used","text":"<ol> <li>The Elements of Statistical Learning</li> <li>Stanford CS229</li> <li>Coursera Machine Learning Specialization</li> </ol>"}]}